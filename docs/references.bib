---
---

@ARTICLE{image-fusion,
author={Li, Shutao and Kang, Xudong and Hu, Jianwen},
journal={IEEE Transactions on Image Processing},
title={Image Fusion With Guided Filtering},
year={2013},
volume={22},
number={7},
pages={2864-2875},
doi={10.1109/TIP.2013.2244222}
}

@InProceedings{guided-filter,
author="He, Kaiming
and Sun, Jian
and Tang, Xiaoou",
editor="Daniilidis, Kostas
and Maragos, Petros
and Paragios, Nikos",
title="Guided Image Filtering",
booktitle="Computer Vision -- ECCV 2010",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--14",
abstract="In this paper, we propose a novel type of explicit image filter - guided filter. Derived from a local linear model, the guided filter generates the filtering output by considering the content of a guidance image, which can be the input image itself or another different image. The guided filter can perform as an edge-preserving smoothing operator like the popular bilateral filter [1], but has better behavior near the edges. It also has a theoretical connection with the matting Laplacian matrix [2], so is a more generic concept than a smoothing operator and can better utilize the structures in the guidance image. Moreover, the guided filter has a fast and non-approximate linear-time algorithm, whose computational complexity is independent of the filtering kernel size. We demonstrate that the guided filter is both effective and efficient in a great variety of computer vision and computer graphics applications including noise reduction, detail smoothing/enhancement, HDR compression, image matting/feathering, haze removal, and joint upsampling.",
isbn="978-3-642-15549-9"
}

@article{petrovic,
author = {Petrovic, Vladimir},
year = {2007},
month = {04},
pages = {208â€“216},
title = {Subjective tests for image fusion evaluation and objective metric validation},
volume = {8},
journal = {Information Fusion},
doi = {10.1016/j.inffus.2005.05.001}
}

@article{lytro,
title = {Multi-focus image fusion using dictionary-based sparse representation},
journal = {Information Fusion},
volume = {25},
pages = {72-84},
year = {2015},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2014.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S1566253514001213},
author = {Mansour Nejati and Shadrokh Samavi and Shahram Shirani},
keywords = {Multi-focus image fusion, Dictionary learning, K-SVD, Sparse representation, Guided image filtering},
abstract = {Multi-focus image fusion has emerged as a major topic in image processing to generate all-focus images with increased depth-of-field from multi-focus photographs. Different approaches have been used in spatial or transform domain for this purpose. But most of them are subject to one or more of image fusion quality degradations such as blocking artifacts, ringing effects, artificial edges, halo artifacts, contrast decrease, sharpness reduction, and misalignment of decision map with object boundaries. In this paper we present a novel multi-focus image fusion method in spatial domain that utilizes a dictionary which is learned from local patches of source images. Sparse representation of relative sharpness measure over this trained dictionary are pooled together to get the corresponding pooled features. Correlation of the pooled features with sparse representations of input images produces a pixel level score for decision map of fusion. Final regularized decision map is obtained using Markov Random Field (MRF) optimization. We also gathered a new color multi-focus image dataset which has more variety than traditional multi-focus image sets. Experimental results demonstrate that our proposed method outperforms existing state-of-the-art methods, in terms of visual and quantitative evaluations.}
}

@ARTICLE{multiexposure,
author = {Ma, Kede and Zeng, Kai and Wang, Zhou},
journal = {IEEE Transactions on Image Processing},
title = {Perceptual Quality Assessment for Multi-Exposure Image Fusion},
year = {2015},
volume = {24},
number = {11},
pages = {3345-3356},
doi = {10.1109/TIP.2015.2442920}
}
